Red Hat Enterprise Linux AI is a foundation model platform to seamlessly develop, test, and run Granite family large language models (LLMs) for enterprise applications. Artificial intelligence (AI) model training requires optimized hardware and powerful computation capabilities. Get more from Red Hat Enterprise Linux AI by extending it with other integrated services and products.
How Red Hat Enterprise Linux AI works
Red Hat Enterprise Linux AI brings together:
The Granite family of open source-licensed LLMs, distributed under the Apache-2.0 license with complete transparency on training datasets.
InstructLab model alignment tools, which open the world of community-developed LLMs to a wide range of users.
A bootable image of Red Hat Enterprise Linux, including popular AI libraries such as PyTorch and hardware optimized inference for NVIDIA, Intel, and AMD.
Enterprise-grade technical support and Open Source Assurance legal protections. 
Red Hat Enterprise Linux AI allows portability across hybrid cloud environments, and makes it possible to then scale your AI workflows with Red Hat OpenShift® AI and to advance to IBM watsonx.ai with additional capabilities for enterprise AI development, data management, and model governance.
Take control of LLMs with open source
Generative AI (gen AI) is a catalyst for groundbreaking change, disrupting everything from how software is made to how we communicate. But frequently, the LLMs used for gen AI are tightly controlled, and cannot be evaluated or improved without specialized skills and high costs.

The future shouldn’t be in the hands of the few. With Red Hat Enterprise Linux AI and its open source approach, you can encourage gen AI innovation with trust and transparency, while lowering costs and removing barriers to entry.

You can even contribute directly to AI model development with InstructLab, a community-driven solution for enhancing LLM capabilities.
